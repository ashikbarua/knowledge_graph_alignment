
Our current goal is to generate a list of correspondences between the set of relations of two ontology. We approached by following a rule-based technique, where we exploited element- level schema model to see how the entities are incident to the relations in the graph. At first, we calculated the incidence score of all the entities to each relation, which tells us the kind of relation/activity/ any entity is related to. List of incidence score for all relations are fed into the matching function. Also, a precomputed mapping between the entities of the two graphs are also passed as input data. These mapping between can include all the entities or a subset of entities. The matching function will output a confusion matrix/list of scores showing the confidence score between any pair of relations, where each relation belongs to separate ontology. The matching score between any two relation is calculated by taking the number of common incident nodes with respect to the total number of incident nodes of them. In this work, we leveraged schema level information of the graphs by using a set of rules.

We ran the wiki dataset through another model named PARIS which is an approach for automatic alignment of Ontologies. PARIS stands for Probabilistic Alignment of Relations, Instances, and Schema, which computes the degree of matching based on probability estimates. It interchanges alignment information at the instance level with alignment at the schema level. PARIS takes the input ontologies in n-triple format, and generates alignments between entities, relations and classes in separate files in a preset output directory. In order to calculate the equivalence between any pair of relations, it tries to find out whether one relation is a sub-relation of the other one and vice versa. PARIS generates two files by listing equivalence score between pairs of relations from the two ontology. Thoroughly speaking, one file shows relations from ontology 1 that are super-relations of relations of ontology 2 and vice versa for the 2nd file.

We converted the Wiki dataset from XML to n-triple format by parsing the XML set as an RDF graph and serialized into n-triple format (built-in method in rdf library). Then we run these datasets through PARIS which generates two files by enlisting the relational equivalence scores. We calculated another list of equivalences by taking the product of score from the two super-relations files. Then we compared these scores with our two approaches by selecting AUC as the evaluation metric.
